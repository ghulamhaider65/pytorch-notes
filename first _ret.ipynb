{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "678548f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "994749d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8f53091d-98ef-43de-aae0-2d1d85eb1577\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f53091d-98ef-43de-aae0-2d1d85eb1577')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8f53091d-98ef-43de-aae0-2d1d85eb1577 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8f53091d-98ef-43de-aae0-2d1d85eb1577');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
       "0    842302         M  ...                  0.11890          NaN\n",
       "1    842517         M  ...                  0.08902          NaN\n",
       "2  84300903         M  ...                  0.08758          NaN\n",
       "3  84348301         M  ...                  0.17300          NaN\n",
       "4  84358402         M  ...                  0.07678          NaN\n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4d095356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "06b201cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cb005291",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4d6f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2e32ca25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e6ee9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5486950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, features):\n",
    "        out = self.linear(features)\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "    def loss_function(self, y_pred, y):\n",
    "        # clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # loss\n",
    "        loss = -(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5430745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45f40045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.1271843910217285\n",
      "Epoch 2, Loss: 3.946201801300049\n",
      "Epoch 3, Loss: 4.272742748260498\n",
      "Epoch 4, Loss: 5.244189262390137\n",
      "Epoch 5, Loss: 5.122478008270264\n",
      "Epoch 6, Loss: 4.9130859375\n",
      "Epoch 7, Loss: 4.639063358306885\n",
      "Epoch 8, Loss: 4.5001749992370605\n",
      "Epoch 9, Loss: 4.501636981964111\n",
      "Epoch 10, Loss: 4.500194549560547\n",
      "Epoch 11, Loss: 4.651371955871582\n",
      "Epoch 12, Loss: 4.5231099128723145\n",
      "Epoch 13, Loss: 4.335605144500732\n",
      "Epoch 14, Loss: 4.2562408447265625\n",
      "Epoch 15, Loss: 3.936127185821533\n",
      "Epoch 16, Loss: 3.8095788955688477\n",
      "Epoch 17, Loss: 3.7503881454467773\n",
      "Epoch 18, Loss: 3.5627527236938477\n",
      "Epoch 19, Loss: 3.5248754024505615\n",
      "Epoch 20, Loss: 3.473949909210205\n",
      "Epoch 21, Loss: 3.430544853210449\n",
      "Epoch 22, Loss: 3.381944179534912\n",
      "Epoch 23, Loss: 3.297300338745117\n",
      "Epoch 24, Loss: 3.1966185569763184\n",
      "Epoch 25, Loss: 3.1779227256774902\n",
      "Epoch 26, Loss: 3.1507863998413086\n",
      "Epoch 27, Loss: 3.098832607269287\n",
      "Epoch 28, Loss: 3.076138973236084\n",
      "Epoch 29, Loss: 3.7898905277252197\n",
      "Epoch 30, Loss: 3.173152446746826\n",
      "Epoch 31, Loss: 3.040081739425659\n",
      "Epoch 32, Loss: 2.6296918392181396\n",
      "Epoch 33, Loss: 2.6111538410186768\n",
      "Epoch 34, Loss: 2.744471788406372\n",
      "Epoch 35, Loss: 2.3112733364105225\n",
      "Epoch 36, Loss: 2.1619880199432373\n",
      "Epoch 37, Loss: 2.0676209926605225\n",
      "Epoch 38, Loss: 2.7292842864990234\n",
      "Epoch 39, Loss: 4.895400047302246\n",
      "Epoch 40, Loss: 3.800497531890869\n",
      "Epoch 41, Loss: 2.1807849407196045\n",
      "Epoch 42, Loss: 1.7811627388000488\n",
      "Epoch 43, Loss: 1.543920874595642\n",
      "Epoch 44, Loss: 8.024218559265137\n",
      "Epoch 45, Loss: 8.023996353149414\n",
      "Epoch 46, Loss: 8.023845672607422\n",
      "Epoch 47, Loss: 8.02372932434082\n",
      "Epoch 48, Loss: 8.023634910583496\n",
      "Epoch 49, Loss: 8.023554801940918\n",
      "Epoch 50, Loss: 8.023486137390137\n",
      "Epoch 51, Loss: 8.023423194885254\n",
      "Epoch 52, Loss: 8.023368835449219\n",
      "Epoch 53, Loss: 8.023319244384766\n",
      "Epoch 54, Loss: 8.023274421691895\n",
      "Epoch 55, Loss: 8.02323055267334\n",
      "Epoch 56, Loss: 8.023192405700684\n",
      "Epoch 57, Loss: 8.02315616607666\n",
      "Epoch 58, Loss: 8.02312183380127\n",
      "Epoch 59, Loss: 8.023090362548828\n",
      "Epoch 60, Loss: 8.023059844970703\n",
      "Epoch 61, Loss: 8.023030281066895\n",
      "Epoch 62, Loss: 8.023002624511719\n",
      "Epoch 63, Loss: 8.022976875305176\n",
      "Epoch 64, Loss: 8.022951126098633\n",
      "Epoch 65, Loss: 8.022926330566406\n",
      "Epoch 66, Loss: 8.022903442382812\n",
      "Epoch 67, Loss: 8.022881507873535\n",
      "Epoch 68, Loss: 8.022858619689941\n",
      "Epoch 69, Loss: 8.022838592529297\n",
      "Epoch 70, Loss: 8.022818565368652\n",
      "Epoch 71, Loss: 8.022799491882324\n",
      "Epoch 72, Loss: 8.02277946472168\n",
      "Epoch 73, Loss: 8.022761344909668\n",
      "Epoch 74, Loss: 8.022744178771973\n",
      "Epoch 75, Loss: 8.022727012634277\n",
      "Epoch 76, Loss: 8.022709846496582\n",
      "Epoch 77, Loss: 8.022692680358887\n",
      "Epoch 78, Loss: 8.022677421569824\n",
      "Epoch 79, Loss: 8.022661209106445\n",
      "Epoch 80, Loss: 8.022644996643066\n",
      "Epoch 81, Loss: 8.022631645202637\n",
      "Epoch 82, Loss: 8.022615432739258\n",
      "Epoch 83, Loss: 8.022602081298828\n",
      "Epoch 84, Loss: 8.022587776184082\n",
      "Epoch 85, Loss: 8.022574424743652\n",
      "Epoch 86, Loss: 8.02255916595459\n",
      "Epoch 87, Loss: 8.022547721862793\n",
      "Epoch 88, Loss: 8.02253246307373\n",
      "Epoch 89, Loss: 8.022520065307617\n",
      "Epoch 90, Loss: 8.02250862121582\n",
      "Epoch 91, Loss: 8.02249526977539\n",
      "Epoch 92, Loss: 8.022483825683594\n",
      "Epoch 93, Loss: 8.022472381591797\n",
      "Epoch 94, Loss: 8.022459983825684\n",
      "Epoch 95, Loss: 8.02244758605957\n",
      "Epoch 96, Loss: 8.02243709564209\n",
      "Epoch 97, Loss: 8.022425651550293\n",
      "Epoch 98, Loss: 8.022414207458496\n",
      "Epoch 99, Loss: 8.022403717041016\n",
      "Epoch 100, Loss: 8.022392272949219\n",
      "Epoch 76, Loss: 8.022709846496582\n",
      "Epoch 77, Loss: 8.022692680358887\n",
      "Epoch 78, Loss: 8.022677421569824\n",
      "Epoch 79, Loss: 8.022661209106445\n",
      "Epoch 80, Loss: 8.022644996643066\n",
      "Epoch 81, Loss: 8.022631645202637\n",
      "Epoch 82, Loss: 8.022615432739258\n",
      "Epoch 83, Loss: 8.022602081298828\n",
      "Epoch 84, Loss: 8.022587776184082\n",
      "Epoch 85, Loss: 8.022574424743652\n",
      "Epoch 86, Loss: 8.02255916595459\n",
      "Epoch 87, Loss: 8.022547721862793\n",
      "Epoch 88, Loss: 8.02253246307373\n",
      "Epoch 89, Loss: 8.022520065307617\n",
      "Epoch 90, Loss: 8.02250862121582\n",
      "Epoch 91, Loss: 8.02249526977539\n",
      "Epoch 92, Loss: 8.022483825683594\n",
      "Epoch 93, Loss: 8.022472381591797\n",
      "Epoch 94, Loss: 8.022459983825684\n",
      "Epoch 95, Loss: 8.02244758605957\n",
      "Epoch 96, Loss: 8.02243709564209\n",
      "Epoch 97, Loss: 8.022425651550293\n",
      "Epoch 98, Loss: 8.022414207458496\n",
      "Epoch 99, Loss: 8.022403717041016\n",
      "Epoch 100, Loss: 8.022392272949219\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model  = MySimpleNN(X_train_tensor.shape[1])\n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    # loss computation\n",
    "    loss = model.loss_function(y_pred, y_train_tensor)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # weights update\n",
    "    with torch.no_grad():\n",
    "        model.linear.weight -= learning_rate * model.linear.weight.grad\n",
    "        model.linear.bias -= learning_rate * model.linear.bias.grad\n",
    "\n",
    "    # zero gradients\n",
    "    model.linear.weight.grad.zero_()\n",
    "    model.linear.bias.grad.zero_()\n",
    "\n",
    "    # print loss i each epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0ce92591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.30717146396637 %\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred >= 0.5).float()\n",
    "    accuracy = (y_pred ==y_test_tensor).float().mean()\n",
    "    print(f\"Accuracy: {accuracy.item()*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
